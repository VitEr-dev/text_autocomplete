# text_autocomplete
Учебный проект на курсе Яндекс-Практикум: Инженер по глубокому обучению нейросетей_обработка естественного языка

# Модели
В проекте реализовыны три модели:

##Автодополнение слова, архитектура LSTM
Папка: LSTM_word_autocomplite
Для работы с моделью запустите solution_LSTM_word.ipynb
Реализованы: предобработка исходных текстов, обучение, валидация, тестирование

##Автодополнение текста, архитектура LSTM
Папка: LSTM_sequens_autocomplite
Для работы с моделью запустите solution_LSTM_sequence.ipynb
Реализованы: предобработка исходных текстов, обучение, валидация, тестирование

##Автодополнение текста на предобучененной distilgpt2 
Папка: distilgpt2_text_autocomplite
Для работы с моделью запустите solution_distilgpt2.ipynb
Реализованы: предобработка исходных текстов, тестирование

##Исходные тексты
В проекте используются тексты (короткие твиты), датасет sentimet140
Реализована очистка текстов, решены проблемы с кодировкой.

# Результаты:

Все три реализованные модели требуют доработки и подходят только для продолжения обучения и экспериментов, но НЕ пригодны для практического применения. 
Качество предсказаний чуть лучше чем случайное угадывание. 

На текущем уровне готовности моделей невозможно однозначно говорить о выборе варианта дальнейшего решения. 
Если в результате доработки модели Автодополнение слова, архитектура LSTM, удастся повысить точность минимум до 25%, то это будет хорошая основа для 
решения задачи бизнеса. Пользователю можно будет предложить при написании текстов 3-5 вариантов слов, с учетом выбора подходящего слова/или 
написания собственного слова - предлагать следующие 3-5 вариантов (генерируемых с учетом предыдущего шага) и так далее. Это может 
упростить задачу пользователю и помочь быстрее и удобнее писать тексты. Решение потребует меньше ресурсов на мобильном устройстве, 
чем другие, рассмотренные в проекте модели. Вариант с развитием модели Автодополнение текста, архитектура LSTM, кажется бесперспективным. 
Даже если повысить точность предсказания следующего слова на 25%, качество генерируемого текста из нескольких слов останется низким. 
При этом надо учитывать, что альтернативный вариант Автодополнение текста на предобучененной distilgpt2 "из коробки" работает лучше. 
Использование модели Автодополнение текста на предобучененной distilgpt2 возможно, после доработки и дообучения. 
Потребуется посчитать стоимость решений, требования к ресурсам, проверить соответствие бизнес задаче (сценариям ипользования). 
Есть гипотеза, что, не смотря на осмысленность генерируемых текстов моделью Автодополнения текста на предобучененной distilgpt2 при работе 
модели "из коробке", в соотношении "стоимость решения"-"ценность для бизнеса", эта модель фаворитом не станет.

## Метрики лучших экспериментов

### Автодополнение слова, архитектура LSTM

test_accuracy: 0.14213523076081946
модель правильно предсказывает каждое 7-е слово

test_precision: 0.10495739278243449
из всех предсказанных слов правильных только 10,5%

test_recall: 0.14213523076081946
модель находит только 14,21% от всех правильных слов

test_f1: 0.09003569756588926
низкое качество

total_samples: 128033

### Автодополнение текста, архитектура LSTM

Метрики качества обучения:
Train Loss: 5.0375, Val Loss: 4.9839
Train Accuracy: 0.3617, Val Accuracy: 0.3666

Метрики тестирования:
rouge1: 0.0500
совпадение с 5% униграмм целевого текста. чуть лучше чем случайно

rouge2: 0.0036
совпадение 0,36% биграмм целевого текста. Нет ничего осмысленного

total_samples: 52769.0000

### Автодополнение текста на предобучененной distilgpt2

ROUGE1 Metrics:
  Precision: 0.0522
  Recall:    0.1842
  F1:        0.0719
совпадение с 5% униграмм целевого текста. чуть лучше чем случайно

ROUGE2 Metrics:
  Precision: 0.0050
  Recall:    0.0180
  F1:        0.0064
совпадение 0,50% биграмм целевого текста. Кажется, что ответы осмысленные, но задача не решается, в таргет не попадаем

samples: 992

## Примеры предсказаний

### Автодополнение слова, архитектура LSTM

Пример 1:
Входная последовательность: like budthespud is back on the north side of the library at least until the end of august couldnt
Истинный следующий токен: find
Предсказанный токен: wait
Правильно: ✗
Топ-5 предсказаний:
  Токен wait: 0.0871
  Токен be: 0.0684
  Токен go: 0.0644
  Токен get: 0.0511
  Токен do: 0.0423

Пример 2:
Входная последовательность: mad sick it just keeps getting worse i need rest i think my body is breakin down cant wait for the
Истинный следующий токен: weekend
Предсказанный токен: day
Правильно: ✗
Топ-5 предсказаний:
  Токен day: 0.0259
  Токен time: 0.0162
  Токен way: 0.0131
  Токен other: 0.0104
  Токен same: 0.0091

Пример 3:
Входная последовательность: aaron gave up on the fight with massive but now has the apc working with traktor epic dj sets here
Истинный следующий токен: we
Предсказанный токен: i
Правильно: ✗
Топ-5 предсказаний:
  Токен i: 0.0364
  Токен and: 0.0321
  Токен to: 0.0299
  Токен in: 0.0244
  Токен for: 0.0219

Пример 4:
Входная последовательность: [CLS] missing my twin and familyi bet no one has such a nice twin that she writes a poem about because mine
Истинный следующий токен: did
Предсказанный токен: is
Правильно: ✗
Топ-5 предсказаний:
  Токен is: 0.1715
  Токен was: 0.1053
  Токен ##s: 0.0433
  Токен will: 0.0370
  Токен would: 0.0292

Пример 5:
Входная последовательность: ##yone put peterfacinell to make peterfacinell a trending topic do it fer peter every
Истинный следующий токен: one
Предсказанный токен: time
Правильно: ✗
Топ-5 предсказаний:
  Токен time: 0.1207
  Токен day: 0.1015
  Токен week: 0.0616
  Токен night: 0.0318
  Токен weekend: 0.0300

Пример 8:
Входная последовательность: [CLS] you know i wanna see up also dude i lost my router signal is so low my ps cant connect
Истинный следующий токен: to
Предсказанный токен: to
Правильно: ✓
Топ-5 предсказаний:
  Токен to: 0.1772
  Токен for: 0.0807
  Токен it: 0.0511
  Токен i: 0.0260
  Токен the: 0.0230

### Автодополнение текста, архитектура LSTM

Пока сгенерированные тексты бессмысленные.

Пример 1:
Входной текст: 'taylor is going to keep buffing up for the upcoming twilight sagas as jacob gets'
Целевой текст: 'bigger and bigger and more sexy'
Предсказанный текст: 'gets suck concert boyfriend startedau def petchi aka lost want'
ROUGE-1: 0.0000
ROUGE-2: 0.0000

Пример 2:
Входной текст: 'why limit your story to ch tell all what is annoying you at it'
Целевой текст: 'will help relieve your stress'
Предсказанный текст: 'it have'
ROUGE-1: 0.0000
ROUGE-2: 0.0000

### Автодополнение текста на предобучененной distilgpt2

Это можно читать, кажется, что есть смысл, но не совпадает с таргетом.

Пример 1:
Вход: the only way i can increase my level in this game is to execute a few plots not...
Ожидалось: enough spymasters in my ring to do tasks playspymaster...
Сгенерировано: only to find the best possible number, but also to see the best possible number that i can make to m...

Пример 2:
Вход: looking for flight tickets to los angeles wth mummy maybe me twin and mum can go this summer...
Ожидалось: with friend from school and her mum and sis...
Сгенерировано: and enjoy the beautiful evening.

Пример 3:
Вход: i have awoken this morning to the distinct feeling that a semi truck has run over mr body and...
Ожидалось: then backed up and did it all over again...
Сгенерировано: the driver has already been arrested.
